{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-21T12:42:52.601982Z",
     "iopub.status.busy": "2022-06-21T12:42:52.601602Z",
     "iopub.status.idle": "2022-06-21T12:42:58.800354Z",
     "shell.execute_reply": "2022-06-21T12:42:58.799471Z",
     "shell.execute_reply.started": "2022-06-21T12:42:52.601919Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-21T12:42:58.802860Z",
     "iopub.status.busy": "2022-06-21T12:42:58.802071Z",
     "iopub.status.idle": "2022-06-21T12:42:58.812879Z",
     "shell.execute_reply": "2022-06-21T12:42:58.811296Z",
     "shell.execute_reply.started": "2022-06-21T12:42:58.802822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.1 (default, Dec 11 2020, 09:29:25) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-21T12:42:58.814775Z",
     "iopub.status.busy": "2022-06-21T12:42:58.814247Z",
     "iopub.status.idle": "2022-06-21T12:42:58.842580Z",
     "shell.execute_reply": "2022-06-21T12:42:58.841669Z",
     "shell.execute_reply.started": "2022-06-21T12:42:58.814738Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class TFRecordReader:\n",
    "    def __init__(self, dir, batch_size, classes, shuffle_buffer_size=512, isRGB=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.dir = dir\n",
    "        self.isRGB = isRGB\n",
    "        self.shuffle_buffer_size = shuffle_buffer_size\n",
    "        # label_df = pd.read_csv(label_dir, sep=\";\", names=[\"gesture\"])\n",
    "        # self.label_encoder = preprocessing.LabelEncoder()\n",
    "        # self.label_encoder.fit(label_df[\"gesture\"])\n",
    "        # print(\"No of classes:\", len(self.label_encoder.classes_))\n",
    "\n",
    "        self.label_processor = tf.keras.layers.StringLookup(\n",
    "            num_oov_indices=0, vocabulary=classes,\n",
    "            mask_token=None \n",
    "        )\n",
    "        self.classes = self.label_processor.vocabulary_size()\n",
    "\n",
    "       \n",
    "\n",
    "        self.num_segments = 8\n",
    "        self.new_length = 4\n",
    "        self.num_frames = 36\n",
    "    \n",
    "    def encode_label(self, label):\n",
    "        \n",
    "        label = self.label_processor(label).numpy()\n",
    "  \n",
    "        return label\n",
    "\n",
    "    def parse_tfr_element(self, element):\n",
    "        data = {\n",
    "            'n_clips': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'raw_image': tf.io.FixedLenFeature([], tf.string),\n",
    "            'label': tf.io.FixedLenFeature([], tf.string),\n",
    "        }\n",
    "\n",
    "        content = tf.io.parse_single_example(element, data)\n",
    "\n",
    "        n_clips = content['n_clips']\n",
    "        height = content['height']\n",
    "        width = content['width']\n",
    "        depth = content['depth']\n",
    "        raw_image = content['raw_image']\n",
    "        label = content['label']\n",
    "\n",
    "        # get out 'feature' --our image and reshape appropriatey\n",
    "        feature = tf.io.parse_tensor(raw_image, out_type=tf.uint8)\n",
    "        feature = tf.reshape(feature, shape=[n_clips, height, width, depth])\n",
    "        if not self.isRGB:\n",
    "            feature = tf.image.rgb_to_grayscale(feature)\n",
    "        feature = tf.image.convert_image_dtype(feature, tf.float32)\n",
    "\n",
    "        label = tf.py_function(self.encode_label, inp=(label,), Tout=tf.int32)\n",
    "\n",
    "        return (feature, label)\n",
    "\n",
    "    def get_dataset(self,  pattern:str=\"*_jester.tfrecords\"):\n",
    "\n",
    "        files = glob(self.dir+pattern, recursive=False)\n",
    "\n",
    "        dataset = tf.data.TFRecordDataset(files, compression_type=\"ZLIB\")\n",
    "        dataset = dataset.shuffle(self.shuffle_buffer_size)\n",
    "\n",
    "        dataset = dataset.map(lambda x: self.parse_tfr_element(x), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        # dataset = dataset.filter(lambda x, y: tf.py_function(filter, inp=(x,y), Tout=tf.bool ) )\n",
    "        # dataset = dataset.map(self._sample_indices)\n",
    "\n",
    "        dataset = dataset.batch(self.batch_size)\n",
    "        dataset = dataset.repeat()\n",
    "        \n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _non_random_indices(self):\n",
    "        if self.num_frames > self.num_segments + self.new_length - 1:\n",
    "            tick = (self.num_frames - self.new_length + 1) / float(self.num_segments)\n",
    "            offsets = np.array([int(tick / 2.0 + tick * x) for x in range(self.num_segments)])\n",
    "        else:\n",
    "            offsets = np.zeros((self.num_segments,))\n",
    "        return offsets + 1\n",
    "    \n",
    "    def _random_shift_indices(self):\n",
    "        average_duration = (self.num_frames - self.new_length + 1) // self.num_segments\n",
    "        if average_duration > 0:\n",
    "            offsets = np.multiply(list(range(self.num_segments)), average_duration) + np.random.randint(average_duration,\n",
    "                                                                                                        size=self.num_segments)\n",
    "        elif self.num_frames > self.num_segments:\n",
    "            offsets = np.sort(np.random.randint(self.num_frames - self.new_length + 1, size=self.num_segments))\n",
    "        else:\n",
    "            offsets = np.zeros((self.num_segments,))\n",
    "        return offsets+1\n",
    "\n",
    "    \n",
    "    def _get_sampled_indices(self):\n",
    "        new_indices = []\n",
    "        #  indices = offsets\n",
    "        # indices =  _random_shift()\n",
    "        indices =  self._non_random_indices()\n",
    "        # print(indices)\n",
    "        for seg_ind in indices:\n",
    "            p = int(seg_ind)\n",
    "            for i in range(self.new_length):\n",
    "                # seg_imgs = self._load_image(record.path, p)\n",
    "                # images.extend(seg_imgs)\n",
    "                new_indices.append(p)\n",
    "                if p < self.num_frames:\n",
    "                    p += 1\n",
    "        return new_indices\n",
    "\n",
    "\n",
    "    def _sample_indices(self, feature, label):\n",
    "        indices = self._get_sampled_indices()\n",
    "        # print(\"wtf\")\n",
    "        # print(indices)\n",
    "        return tf.gather(feature, indices=indices), label\n",
    "        # print(new_inp.shape)\n",
    "        # print(new_inp)\n",
    "        # return new_inp\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-21T12:42:58.845451Z",
     "iopub.status.busy": "2022-06-21T12:42:58.844737Z",
     "iopub.status.idle": "2022-06-21T12:42:58.857054Z",
     "shell.execute_reply": "2022-06-21T12:42:58.856214Z",
     "shell.execute_reply.started": "2022-06-21T12:42:58.845413Z"
    }
   },
   "outputs": [],
   "source": [
    "class TubeletEmbedding(layers.Layer):\n",
    "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.patch_size = patch_size\n",
    "        self.projection = layers.Conv3D(\n",
    "            filters=embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            strides=patch_size,\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
    "\n",
    "    def call(self, videos):\n",
    "        projected_patches = self.projection(videos)\n",
    "        flattened_patches = self.flatten(projected_patches)\n",
    "        return flattened_patches\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(TubeletEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"patch_size\": self.patch_size\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-21T12:42:58.858910Z",
     "iopub.status.busy": "2022-06-21T12:42:58.858536Z",
     "iopub.status.idle": "2022-06-21T12:42:58.867717Z",
     "shell.execute_reply": "2022-06-21T12:42:58.866590Z",
     "shell.execute_reply.started": "2022-06-21T12:42:58.858874Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, num_tokens, _ = input_shape\n",
    "        self.num_tokens = num_tokens\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_tokens, output_dim=self.embed_dim\n",
    "        )\n",
    "\n",
    "    def call(self, encoded_tokens):\n",
    "        # Encode the positions and add it to the encoded tokens\n",
    "        positions = tf.range(start=0, limit=self.num_tokens, delta=1)\n",
    "\n",
    "        encoded_positions = self.position_embedding(positions)\n",
    "        encoded_tokens = encoded_tokens + encoded_positions\n",
    "        return encoded_tokens\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "        }\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-21T12:42:58.870033Z",
     "iopub.status.busy": "2022-06-21T12:42:58.869404Z",
     "iopub.status.idle": "2022-06-21T12:42:58.880509Z",
     "shell.execute_reply": "2022-06-21T12:42:58.879451Z",
     "shell.execute_reply.started": "2022-06-21T12:42:58.869997Z"
    }
   },
   "outputs": [],
   "source": [
    "# DATA\n",
    "DATASET_NAME = \"jester\"\n",
    "BATCH_SIZE = 32\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = (36, 100, 100, 1) \n",
    "\n",
    "\n",
    "# OPTIMIZER\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# TRAINING\n",
    "EPOCHS = 60\n",
    "\n",
    "# TUBELET EMBEDDING\n",
    "PATCH_SIZE = (8, 8, 8)\n",
    "NUM_PATCHES = (INPUT_SHAPE[0] // PATCH_SIZE[0]) ** 2\n",
    "\n",
    "# ViViT ARCHITECTURE\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "PROJECTION_DIM = 128\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-21T12:42:58.883849Z",
     "iopub.status.busy": "2022-06-21T12:42:58.883560Z",
     "iopub.status.idle": "2022-06-21T12:42:58.898441Z",
     "shell.execute_reply": "2022-06-21T12:42:58.897350Z",
     "shell.execute_reply.started": "2022-06-21T12:42:58.883801Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_vivit_classifier(\n",
    "    tubelet_embedder,\n",
    "    positional_encoder,\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    transformer_layers=NUM_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    embed_dim=PROJECTION_DIM,\n",
    "    layer_norm_eps=LAYER_NORM_EPS,\n",
    "    num_classes=2,\n",
    "):\n",
    "    # Get the input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Create patches.\n",
    "    patches = tubelet_embedder(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = positional_encoder(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization and MHSA\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # Layer Normalization and MLP\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=embed_dim * 4, activation=tf.nn.gelu),\n",
    "                layers.Dense(units=embed_dim, activation=tf.nn.gelu),\n",
    "            ]\n",
    "        )(x3)\n",
    "\n",
    "        # Skip connection\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Layer normalization and Global average pooling.\n",
    "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
    "    representation = layers.GlobalAvgPool1D()(representation)\n",
    "\n",
    "    # Classify outputs.\n",
    "    outputs = layers.Dense(units=num_classes, activation=\"softmax\")(representation)\n",
    "\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-21T12:42:58.900435Z",
     "iopub.status.busy": "2022-06-21T12:42:58.900015Z",
     "iopub.status.idle": "2022-06-21T12:42:58.908072Z",
     "shell.execute_reply": "2022-06-21T12:42:58.906904Z",
     "shell.execute_reply.started": "2022-06-21T12:42:58.900385Z"
    }
   },
   "outputs": [],
   "source": [
    "filter_ges = [\n",
    "\"Swiping Up\", \"Swiping Down\", \"Swiping Left\", \"Swiping Right\",\n",
    "\"Zooming In With Two Fingers\",\"Zooming Out With Two Fingers\",\n",
    "\"Zooming In With Full Hand\",\"Zooming Out With Full Hand\",\"Turning Hand Clockwise\",\n",
    "\"Turning Hand Counterclockwise\",\"Thumb Up\",\"Thumb Down\",\"Shaking Hand\",\n",
    "\"Stop Sign\",\"Doing other things\",\"No gesture\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-21T12:42:58.910324Z",
     "iopub.status.busy": "2022-06-21T12:42:58.909991Z",
     "iopub.status.idle": "2022-06-21T12:43:02.063619Z",
     "shell.execute_reply": "2022-06-21T12:43:02.061971Z",
     "shell.execute_reply.started": "2022-06-21T12:42:58.910292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Class:16 VAL Class:16\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "NUM_CLASSES = len(filter_ges)\n",
    "\n",
    "train_ds_gen = TFRecordReader(dir=\"../input/20bn-jester-tfrecord-16-classes/train/\",batch_size=BATCH_SIZE,shuffle_buffer_size=32,classes=filter_ges, isRGB=False)\n",
    "train_ds = train_ds_gen.get_dataset()\n",
    "\n",
    "val_ds_gen = TFRecordReader(dir=\"../input/20bn-jester-tfrecord-16-classes/validation/\",batch_size=BATCH_SIZE, shuffle_buffer_size=32,classes=filter_ges, isRGB=False)\n",
    "val_ds = val_ds_gen.get_dataset()\n",
    "\n",
    "print(f\"TRAIN Class:{train_ds_gen.classes} VAL Class:{val_ds_gen.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-21T12:43:02.066955Z",
     "iopub.status.busy": "2022-06-21T12:43:02.066669Z",
     "iopub.status.idle": "2022-06-21T12:43:03.096670Z",
     "shell.execute_reply": "2022-06-21T12:43:03.094871Z",
     "shell.execute_reply.started": "2022-06-21T12:43:02.066930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 36, 100, 10  0           []                               \n",
      "                                0, 1)]                                                            \n",
      "                                                                                                  \n",
      " tubelet_embedding_1 (TubeletEm  (None, 576, 128)    65664       ['input_2[0][0]']                \n",
      " bedding)                                                                                         \n",
      "                                                                                                  \n",
      " positional_encoder_1 (Position  (None, 576, 128)    73728       ['tubelet_embedding_1[0][0]']    \n",
      " alEncoder)                                                                                       \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 576, 128)    256         ['positional_encoder_1[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 576, 128)    66048       ['layer_normalization_17[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 576, 128)     0           ['multi_head_attention_8[0][0]', \n",
      "                                                                  'positional_encoder_1[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 576, 128)    256         ['add_16[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_8 (Sequential)      (None, 576, 128)     131712      ['layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 576, 128)     0           ['sequential_8[0][0]',           \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 576, 128)    256         ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 576, 128)    66048       ['layer_normalization_19[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 576, 128)     0           ['multi_head_attention_9[0][0]', \n",
      "                                                                  'add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 576, 128)    256         ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_9 (Sequential)      (None, 576, 128)     131712      ['layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 576, 128)     0           ['sequential_9[0][0]',           \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 576, 128)    256         ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 576, 128)    66048       ['layer_normalization_21[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 576, 128)     0           ['multi_head_attention_10[0][0]',\n",
      "                                                                  'add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 576, 128)    256         ['add_20[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_10 (Sequential)     (None, 576, 128)     131712      ['layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 576, 128)     0           ['sequential_10[0][0]',          \n",
      "                                                                  'add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 576, 128)    256         ['add_21[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 576, 128)    66048       ['layer_normalization_23[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 576, 128)     0           ['multi_head_attention_11[0][0]',\n",
      "                                                                  'add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 576, 128)    256         ['add_22[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_11 (Sequential)     (None, 576, 128)     131712      ['layer_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 576, 128)     0           ['sequential_11[0][0]',          \n",
      "                                                                  'add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 576, 128)    256         ['add_23[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (Multi  (None, 576, 128)    66048       ['layer_normalization_25[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 576, 128)     0           ['multi_head_attention_12[0][0]',\n",
      "                                                                  'add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_26 (LayerN  (None, 576, 128)    256         ['add_24[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_12 (Sequential)     (None, 576, 128)     131712      ['layer_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 576, 128)     0           ['sequential_12[0][0]',          \n",
      "                                                                  'add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, 576, 128)    256         ['add_25[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_13 (Multi  (None, 576, 128)    66048       ['layer_normalization_27[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 576, 128)     0           ['multi_head_attention_13[0][0]',\n",
      "                                                                  'add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, 576, 128)    256         ['add_26[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_13 (Sequential)     (None, 576, 128)     131712      ['layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 576, 128)     0           ['sequential_13[0][0]',          \n",
      "                                                                  'add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, 576, 128)    256         ['add_27[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (Multi  (None, 576, 128)    66048       ['layer_normalization_29[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 576, 128)     0           ['multi_head_attention_14[0][0]',\n",
      "                                                                  'add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, 576, 128)    256         ['add_28[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_14 (Sequential)     (None, 576, 128)     131712      ['layer_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 576, 128)     0           ['sequential_14[0][0]',          \n",
      "                                                                  'add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_31 (LayerN  (None, 576, 128)    256         ['add_29[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_15 (Multi  (None, 576, 128)    66048       ['layer_normalization_31[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 576, 128)     0           ['multi_head_attention_15[0][0]',\n",
      "                                                                  'add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_32 (LayerN  (None, 576, 128)    256         ['add_30[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sequential_15 (Sequential)     (None, 576, 128)     131712      ['layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 576, 128)     0           ['sequential_15[0][0]',          \n",
      "                                                                  'add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, 576, 128)    256         ['add_31[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 128)         0           ['layer_normalization_33[0][0]'] \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 16)           2064        ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,727,888\n",
      "Trainable params: 1,727,888\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_vivit_classifier(\n",
    "        tubelet_embedder=TubeletEmbedding(\n",
    "            embed_dim=PROJECTION_DIM, patch_size=PATCH_SIZE\n",
    "        ),\n",
    "        positional_encoder=PositionalEncoder(embed_dim=PROJECTION_DIM),\n",
    "        num_classes=NUM_CLASSES\n",
    "    )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-21T12:43:03.098435Z",
     "iopub.status.busy": "2022-06-21T12:43:03.098092Z",
     "iopub.status.idle": "2022-06-21T12:43:03.112742Z",
     "shell.execute_reply": "2022-06-21T12:43:03.111818Z",
     "shell.execute_reply.started": "2022-06-21T12:43:03.098399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate an optimizer to train the model.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "# Instantiate a loss function.\n",
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Prepare the metrics.\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "train_top5_acc_metric = keras.metrics.SparseTopKCategoricalAccuracy(k=5)\n",
    "# val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "filepath =\"./checkpoint\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-21T12:43:03.114543Z",
     "iopub.status.busy": "2022-06-21T12:43:03.114213Z",
     "iopub.status.idle": "2022-06-21T12:43:03.129856Z",
     "shell.execute_reply": "2022-06-21T12:43:03.129098Z",
     "shell.execute_reply.started": "2022-06-21T12:43:03.114489Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[train_acc_metric, train_top5_acc_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-21T12:43:03.131618Z",
     "iopub.status.busy": "2022-06-21T12:43:03.131257Z"
    }
   },
   "outputs": [],
   "source": [
    "# Classes 16\n",
    "steps_per_epoch = np.ceil(71724/ train_ds_gen.batch_size)\n",
    "val_steps_per_epoch = np.ceil(9036/ val_ds_gen.batch_size)\n",
    "# Classees3\n",
    "# steps_per_epoch = np.ceil(12524/ train_ds_gen.batch_size)\n",
    "# val_steps_per_epoch = np.ceil(1513/ val_ds_gen.batch_size)\n",
    "\n",
    "# model.fit(\n",
    "#         train_ds,\n",
    "#         validation_data=val_ds,\n",
    "#         steps_per_epoch = steps_per_epoch,\n",
    "#         validation_steps=val_steps_per_epoch,\n",
    "#         callbacks=[checkpoint],\n",
    "#         epochs=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save( os.path.join(os.getcwd(),  \"saved_model\", \"classes16_model.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: TubeletEmbedding. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-3c24f300c703>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# loaded_model = tf.keras.models.load_model(\"./classes16_model (1)\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mloaded_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"classes16_model (1)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\datn\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[1;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    560\u001b[0m   \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_registered_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;34mf'Unknown {printable_module_name}: {class_name}. Please ensure this '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[1;34m'object is passed to the `custom_objects` argument. See '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown layer: TubeletEmbedding. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "# loaded_model = tf.keras.models.load_model(\"./classes16_model (1)\")\n",
    "loaded_model = tf.keras.models.load_model(os.path.join(os.getcwd(), \"classes16_model (1)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels  = next(iter(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred = loaded_model.predict(images)\n",
    "\n",
    "pred_gesture = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_gesture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "filter_ges = [\n",
    "\"Swiping Up\", \"Swiping Down\", \"Swiping Left\", \"Swiping Right\",\n",
    "\"Zooming In With Two Fingers\",\"Zooming Out With Two Fingers\",\n",
    "\"Zooming In With Full Hand\",\"Zooming Out With Full Hand\",\"Turning Hand Clockwise\",\n",
    "\"Turning Hand Counterclockwise\",\"Thumb Up\",\"Thumb Down\",\"Shaking Hand\",\n",
    "\"Stop Sign\",\"Doing other things\",\"No gesture\"\n",
    "]\n",
    "\n",
    "for i in range(8):\n",
    "    fig, axs = plt.subplots(1, 6)\n",
    "    for j in range(6):\n",
    "\n",
    "        axs[ j].imshow(images[i][(j+1)*6-1])\n",
    "        axs[j].axis(\"off\")\n",
    "        # axs[ j].set_title(f'{filter_ges[pred_gesture[i]]}')\n",
    "    plt.title(f'Predicted:: {filter_ges[pred_gesture[i]]}         Label::{filter_ges[labels[i]]}')\n",
    " \n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c0b6a750aca8972aae7845e3faf2881bbed23e45a4a6d5cb44577fc7d129e52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
